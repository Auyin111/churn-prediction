{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from lib.churn_prediction import ChurnPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_data = pd.read_csv('D:\\data\\churn_prediction//Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((1.2 - 0.63) * 100 + (1 - 0.63) * 100 - 6 ) * 7.8   # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# churn_prediction.df_all_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of combination: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>dropout_percent</th>\n",
       "      <th>list_layers_input_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr  batch_size  shuffle class_weight  dropout_percent  \\\n",
       "0  0.010        1000     True         None              0.4   \n",
       "1  0.010        1000    False         None              0.4   \n",
       "2  0.001        1000     True         None              0.4   \n",
       "3  0.001        1000    False         None              0.4   \n",
       "\n",
       "  list_layers_input_size  \n",
       "0         [200, 100, 50]  \n",
       "1         [200, 100, 50]  \n",
       "2         [200, 100, 50]  \n",
       "3         [200, 100, 50]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and valid model:  _lr_0.01_dropout_p_0.4_layers_size_[200,100,50]_bs_1000_shuffle_True_no_cw\n",
      "Validation loss decreased (inf --> 0.748686).  Saving model ...\n",
      "Validation loss decreased (0.748686 --> 0.693153).  Saving model ...\n",
      "Validation loss decreased (0.693153 --> 0.413493).  Saving model ...\n",
      "Validation loss decreased (0.413493 --> 0.347103).  Saving model ...\n",
      "Validation loss decreased (0.347103 --> 0.336516).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 2\n",
      "Validation loss decreased (0.336516 --> 0.330267).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 2\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Early stopping at 9\n",
      "train and valid model:  _lr_0.01_dropout_p_0.4_layers_size_[200,100,50]_bs_1000_shuffle_False_no_cw\n",
      "Validation loss decreased (inf --> 0.984820).  Saving model ...\n",
      "Validation loss decreased (0.984820 --> 0.625403).  Saving model ...\n",
      "Validation loss decreased (0.625403 --> 0.420121).  Saving model ...\n",
      "Validation loss decreased (0.420121 --> 0.384674).  Saving model ...\n",
      "Validation loss decreased (0.384674 --> 0.365068).  Saving model ...\n",
      "Validation loss decreased (0.365068 --> 0.359753).  Saving model ...\n",
      "Validation loss decreased (0.359753 --> 0.357621).  Saving model ...\n",
      "Validation loss decreased (0.357621 --> 0.350398).  Saving model ...\n",
      "Validation loss decreased (0.350398 --> 0.345748).  Saving model ...\n",
      "Validation loss decreased (0.345748 --> 0.343850).  Saving model ...\n",
      "Validation loss decreased (0.343850 --> 0.342224).  Saving model ...\n",
      "Validation loss decreased (0.342224 --> 0.341205).  Saving model ...\n",
      "Validation loss decreased (0.341205 --> 0.338978).  Saving model ...\n",
      "Validation loss decreased (0.338978 --> 0.337861).  Saving model ...\n",
      "Validation loss decreased (0.337861 --> 0.336879).  Saving model ...\n",
      "Validation loss decreased (0.336879 --> 0.335377).  Saving model ...\n",
      "Validation loss decreased (0.335377 --> 0.333178).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 2\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Early stopping at 19\n",
      "train and valid model:  _lr_0.001_dropout_p_0.4_layers_size_[200,100,50]_bs_1000_shuffle_True_no_cw\n",
      "Validation loss decreased (inf --> 0.638191).  Saving model ...\n",
      "Validation loss decreased (0.638191 --> 0.580850).  Saving model ...\n",
      "Validation loss decreased (0.580850 --> 0.526215).  Saving model ...\n",
      "Validation loss decreased (0.526215 --> 0.490677).  Saving model ...\n",
      "Validation loss decreased (0.490677 --> 0.469128).  Saving model ...\n",
      "Validation loss decreased (0.469128 --> 0.453406).  Saving model ...\n",
      "Validation loss decreased (0.453406 --> 0.440160).  Saving model ...\n",
      "Validation loss decreased (0.440160 --> 0.427482).  Saving model ...\n",
      "Validation loss decreased (0.427482 --> 0.415755).  Saving model ...\n",
      "Validation loss decreased (0.415755 --> 0.407701).  Saving model ...\n",
      "Validation loss decreased (0.407701 --> 0.400612).  Saving model ...\n",
      "Validation loss decreased (0.400612 --> 0.394259).  Saving model ...\n",
      "Validation loss decreased (0.394259 --> 0.388718).  Saving model ...\n",
      "Validation loss decreased (0.388718 --> 0.383486).  Saving model ...\n",
      "Validation loss decreased (0.383486 --> 0.376687).  Saving model ...\n",
      "Validation loss decreased (0.376687 --> 0.372950).  Saving model ...\n",
      "Validation loss decreased (0.372950 --> 0.369396).  Saving model ...\n",
      "Validation loss decreased (0.369396 --> 0.365491).  Saving model ...\n",
      "Validation loss decreased (0.365491 --> 0.364277).  Saving model ...\n",
      "Validation loss decreased (0.364277 --> 0.362321).  Saving model ...\n",
      "train and valid model:  _lr_0.001_dropout_p_0.4_layers_size_[200,100,50]_bs_1000_shuffle_False_no_cw\n",
      "Validation loss decreased (inf --> 0.822616).  Saving model ...\n",
      "Validation loss decreased (0.822616 --> 0.759604).  Saving model ...\n",
      "Validation loss decreased (0.759604 --> 0.677280).  Saving model ...\n",
      "Validation loss decreased (0.677280 --> 0.611769).  Saving model ...\n",
      "Validation loss decreased (0.611769 --> 0.566819).  Saving model ...\n",
      "Validation loss decreased (0.566819 --> 0.536264).  Saving model ...\n",
      "Validation loss decreased (0.536264 --> 0.515208).  Saving model ...\n",
      "Validation loss decreased (0.515208 --> 0.498635).  Saving model ...\n",
      "Validation loss decreased (0.498635 --> 0.484158).  Saving model ...\n",
      "Validation loss decreased (0.484158 --> 0.469818).  Saving model ...\n",
      "Validation loss decreased (0.469818 --> 0.458601).  Saving model ...\n",
      "Validation loss decreased (0.458601 --> 0.447453).  Saving model ...\n",
      "Validation loss decreased (0.447453 --> 0.437084).  Saving model ...\n",
      "Validation loss decreased (0.437084 --> 0.425430).  Saving model ...\n",
      "Validation loss decreased (0.425430 --> 0.415095).  Saving model ...\n",
      "Validation loss decreased (0.415095 --> 0.408316).  Saving model ...\n",
      "Validation loss decreased (0.408316 --> 0.402654).  Saving model ...\n",
      "Validation loss decreased (0.402654 --> 0.394875).  Saving model ...\n",
      "Validation loss decreased (0.394875 --> 0.387027).  Saving model ...\n",
      "Validation loss decreased (0.387027 --> 0.382261).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "churn_prediction = ChurnPrediction(df_all_data, is_display_detail = False)\n",
    "churn_prediction.find_best_parmas_by_valid_loss(num_epochs = 20, patience = 2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.883382</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.911278</td>\n",
       "      <td>1610.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.562963</td>\n",
       "      <td>390.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.8525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.775024</td>\n",
       "      <td>0.714087</td>\n",
       "      <td>0.737121</td>\n",
       "      <td>2000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.841122</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.843357</td>\n",
       "      <td>2000.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score    support\n",
       "0              0.883382  0.940994  0.911278  1610.0000\n",
       "1              0.666667  0.487179  0.562963   390.0000\n",
       "accuracy       0.852500  0.852500  0.852500     0.8525\n",
       "macro avg      0.775024  0.714087  0.737121  2000.0000\n",
       "weighted avg   0.841122  0.852500  0.843357  2000.0000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_prediction.test_model()\n",
    "churn_prediction.show_test_set_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>dropout_percent</th>\n",
       "      <th>list_layers_input_size</th>\n",
       "      <th>parmas_desc</th>\n",
       "      <th>best_valid_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>_lr_0.01_dropout_p_0.4_layers_size_[200,100,50...</td>\n",
       "      <td>0.330267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>_lr_0.01_dropout_p_0.4_layers_size_[200,100,50...</td>\n",
       "      <td>0.333178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>_lr_0.001_dropout_p_0.4_layers_size_[200,100,5...</td>\n",
       "      <td>0.362321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[200, 100, 50]</td>\n",
       "      <td>_lr_0.001_dropout_p_0.4_layers_size_[200,100,5...</td>\n",
       "      <td>0.382261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr  batch_size  shuffle class_weight  dropout_percent  \\\n",
       "0  0.010        1000     True         None              0.4   \n",
       "1  0.010        1000    False         None              0.4   \n",
       "2  0.001        1000     True         None              0.4   \n",
       "3  0.001        1000    False         None              0.4   \n",
       "\n",
       "  list_layers_input_size                                        parmas_desc  \\\n",
       "0         [200, 100, 50]  _lr_0.01_dropout_p_0.4_layers_size_[200,100,50...   \n",
       "1         [200, 100, 50]  _lr_0.01_dropout_p_0.4_layers_size_[200,100,50...   \n",
       "2         [200, 100, 50]  _lr_0.001_dropout_p_0.4_layers_size_[200,100,5...   \n",
       "3         [200, 100, 50]  _lr_0.001_dropout_p_0.4_layers_size_[200,100,5...   \n",
       "\n",
       "   best_valid_loss  \n",
       "0         0.330267  \n",
       "1         0.333178  \n",
       "2         0.362321  \n",
       "3         0.382261  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_prediction.df_validation_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNModel(\n",
       "  (all_embeddings): ModuleList(\n",
       "    (0): Embedding(3, 2)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(2, 1)\n",
       "  )\n",
       "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
       "  (batch_norm_num): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=11, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Dropout(p=0.4, inplace=False)\n",
       "    (12): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_prediction.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prediction.df_validation_performance.loc[0, 'parmas_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in churn_prediction.list_train_valid_model:\n",
    "    if model.parmas_desc == churn_prediction.df_validation_performance.loc[0, 'parmas_desc']:\n",
    "        print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = churn_prediction.df_validation_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __prepare_model_desc(self):\n",
    "    \"\"\"mark down the detail time and parmas\"\"\"\n",
    "\n",
    "    self.str_ymd_hms = datetime.datetime.now().strftime('%Y_%m_%d__%H_%M_%S')\n",
    "\n",
    "    # __________all parmas__________\n",
    "    self.str_parmas = ''\n",
    "\n",
    "    # optimizer_parmas\n",
    "    self.str_parmas += f'_lr_{self.lr}'\n",
    "\n",
    "    # model_parmas\n",
    "    self.str_parmas += f'_dropout_p_{self.dropout_percent}'\n",
    "    # [1,2,3,4] --> '[1,2,3,4]'\n",
    "    self.str_parmas += f\"_layers_size_[{','.join(str(size) for size in self.list_layers_input_size)}]\"\n",
    "\n",
    "    # dataloader_parmas\n",
    "    self.str_parmas += f'_bs_{self.batch_size}'\n",
    "    self.str_parmas += f'_shuffle_{self.shuffle}'\n",
    "\n",
    "    # loss_function_parmas\n",
    "    if self.class_weight is not None:\n",
    "        self.str_parmas += f'_cw_{self.class_weight[0]:.2f}_{self.class_weight[1]:.2f}'\n",
    "    else:\n",
    "        self.str_parmas += '_no_cw'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prediction.list_train_valid_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_parmas_desc = []\n",
    "list_best_valid_loss = []\n",
    "\n",
    "for model in churn_prediction.list_train_valid_model:\n",
    "    list_parmas_desc.append(model.parmas_desc)\n",
    "    list_best_valid_loss.append(model.best_valid_loss)\n",
    "\n",
    "df_best_valid_loss = pd.DataFrame({'parmas_desc':list_parmas_desc, 'best_valid_loss':list_best_valid_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(churn_prediction.df_all_combinations, df_best_valid_loss, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {}\n",
    "for idx, model in enumerate(churn_prediction.list_train_valid_model):\n",
    "    \n",
    "    str_model = f'model_{idx + 1}'\n",
    "    \n",
    "    if 'best_score' not in dict_.keys():\n",
    "        dict_[str_model] = 'best_score'\n",
    "    \n",
    "    dict_[str_model]['best_score'] = model.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_[str_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{model.parmas:model.best_score for idx, model in enumerate(churn_prediction.list_train_valid_model)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({model.parmas:model.best_score for model in churn_prediction.list_train_valid_model}, index = [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prediction.list_train_valid_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prediction_class_weight = ChurnPrediction(df_all_data)\n",
    "\n",
    "churn_prediction_class_weight.train_valid_model(num_epochs = 100, patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prediction_class_weight.test_model()\n",
    "churn_prediction_class_weight.show_test_set_classification_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
